{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RWAxHJI0szqz"
   },
   "source": [
    "# **INTERNSHIP STUDIO PROJECT :- MARKETING CAMPAIGN FOR BANK PRODUCTS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is about a bank finding the more reliable persons for converting them to person loan customers. They have a previous experience of doing a campaign and collected the data from different customers and found that 9 percent of 5000 people converted to personal loan customers. So they dont want to waste time again this this time for visiting all 5000 customers just for mere 9 percent though it was healthy. So we need to build a model such that we can filter customers who have maximum probability to convert into personal loan customers so that the bank can concentrate on those people only and can easily increase the percentage and reduce the cost for campaign this time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1)Laoding the data and analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tcyZc_QCudRL"
   },
   "source": [
    "**First we import all the required libraries for the project**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "iuQUDzVupRs7",
    "outputId": "66d1023e-7139-4878-9ce0-16134b839e57"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZFTvSov9uV3_"
   },
   "source": [
    "**we now load the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(r\"C:\\Users\\LAKSHMI SAI KRISHNA\\Desktop\\Bank_Personal_Loan_Modelling.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "colab_type": "code",
    "id": "fAU3_4Iduy2K",
    "outputId": "b0e903f6-e7b2-421e-df9a-116c0f820678"
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e_h_lYhxzu6L"
   },
   "source": [
    "**let us check out the shape, size, dtypes,no of dimensions of the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ISWiGnL2y5Ao",
    "outputId": "a332ce3e-0428-4b7d-f9e6-20dc077051c9"
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "A5LjhnRNztcE",
    "outputId": "9118c4a7-52cf-447c-ee2f-969fa20a477c"
   },
   "outputs": [],
   "source": [
    "data.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "xJk73Ywu24bt",
    "outputId": "802e9e2b-355d-495d-93a1-80469f031ec8"
   },
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "28jd7F9Y28cj",
    "outputId": "c3b53baf-ef04-42ec-e6af-78cc96437531"
   },
   "outputs": [],
   "source": [
    "data.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8v24owZs0BR3"
   },
   "source": [
    "**List of column names**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "xRv2Wkl0z4u8",
    "outputId": "e539b6ac-a53b-479a-b9bf-ac20e1351ed1"
   },
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vu3L1ZXf0gud"
   },
   "source": [
    "**First 5 rows and last 5 rows of the data**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "zayPHNy1z_Td",
    "outputId": "e101c9b1-bbc0-419e-c7bd-5f5bbb72d01d"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "TQ-PRCkm0Sy1",
    "outputId": "fefea4a6-1d02-4c02-ab8b-17fca75765b2"
   },
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4_W7j8m01Wcg"
   },
   "source": [
    "**Info regarding the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "colab_type": "code",
    "id": "zd99J-To0VRO",
    "outputId": "63b6ae9c-2563-421e-b6e4-793ba4974377"
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VeZSHXTi1Zda"
   },
   "source": [
    "**From info the observed points are**\n",
    "\n",
    "1. there are total 5000 rows in the given dataset\n",
    "2. there are 14 columns in the given dataset\n",
    "3. out of all the 14 columns 13 columns are of integer type and only 1 column  is of float datatype\n",
    "4. there are no null values in the data\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lfIHbYqr3aYc"
   },
   "source": [
    "## **Statistical summary of data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "colab_type": "code",
    "id": "w1L25b7z1Ulv",
    "outputId": "e99a12d7-614a-4f52-a6db-afe4f9066712"
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "Ipjdd7vb4DgY",
    "outputId": "92b79419-9762-442d-e7ec-b7b87c09e5bf"
   },
   "outputs": [],
   "source": [
    "data.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "v4a3_x2j3hIV",
    "outputId": "2784e312-3408-4b03-ede1-a834313d1852"
   },
   "outputs": [],
   "source": [
    "data['Age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mbjvvsO05nZE",
    "outputId": "7e62284b-7617-4f3f-fdbd-0054f5458fba"
   },
   "outputs": [],
   "source": [
    "data['Age'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "To0pFJQS5seI",
    "outputId": "466e1b88-62a9-47a4-ad61-3feb75537f4e"
   },
   "outputs": [],
   "source": [
    "data['Age'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YvTbyp5K9Drp"
   },
   "source": [
    "#### **Inference from statistical summary**\n",
    "\n",
    "\n",
    "1.  The last 4 columns are binary type categorical data\n",
    "2.  From datatypes it can be said that except ccaverage column all other columns are discrete\n",
    "3.  Experience column has a minimum value of -3 so it means there are negative values in the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5lZkcuv55d4x"
   },
   "source": [
    "### **Let us check for any null values present in data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "colab_type": "code",
    "id": "Pgn6BgHO4Axc",
    "outputId": "52da8855-dceb-4cb8-f1cf-65fc311bd2ee"
   },
   "outputs": [],
   "source": [
    "data.isna()\n",
    "#this just gives boolean values throughout the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "colab_type": "code",
    "id": "ffSVvss56x_E",
    "outputId": "9514b669-00f9-4d10-93f7-47d1ffc56e67"
   },
   "outputs": [],
   "source": [
    "pd.isnull(data).any(axis=1)\n",
    "#this gives boolean along the axis 1 i.e rows for null values if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "tW94vNEbDRw8",
    "outputId": "7cd6b77f-ba87-445c-ae1c-568304596a56"
   },
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 47
    },
    "colab_type": "code",
    "id": "XzsEx-2v7D07",
    "outputId": "a4e2eb54-1697-4078-9be6-b88fc96ddc21"
   },
   "outputs": [],
   "source": [
    "data[pd.isnull(data).any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dz6WUcs972k6"
   },
   "source": [
    "### **Therefore no rows are displayed which implies there are no missing values in the given dataset**\n",
    " So there is no need to clean the null values since data is already free from null values but there is still some data cleaning required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2) Data Cleaning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### it is very clear that id is just like a serial number and anyhow we had index for that purpose\n",
    "#### Let us remove that column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(labels=\"ID\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From statistical summary we got to know that experience column has negative values and we dont konw whether the negative values are from data collection errors or they are signifying 0 experience \n",
    "so we fill all the negative columns with the median of experience column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(np.median(data.Experience))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Experience=data['Experience'].replace([-1,-2,-3],int(np.median(data['Experience'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Experience.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let us check for any duplicated rows so that we can keep the repeated rows only single time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore no duplicated rows in th cleaned dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note:-\n",
    "1. **Until now we cleaned the data as much as possible from the data analysis but still we dont know which columns are highly correlated so that we can remove one of them**\n",
    "2. **It is hard here itself to identify these pairs of correlation** \n",
    "3. **it will be easy if we use EDA and visualise the plots between columns to recognise any strong correlations**\n",
    "4. **This we will do in the visualisation and do the left over cleaning there**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TDFE5CtbVHV9"
   },
   "source": [
    "# **3) EDA (Exploratory Data Analysis)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wgSr_-PzVrUq"
   },
   "source": [
    "**Let us find all the unique values in each columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "A9lEfNz57tIw",
    "outputId": "f2fe1afe-a9d0-4307-d316-85c0c03ffd5f"
   },
   "outputs": [],
   "source": [
    "data.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "xtAT-82MCtPo",
    "outputId": "59372621-2c6a-40eb-d859-9e2160daafe6"
   },
   "outputs": [],
   "source": [
    "np.sort(data['Age'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "Kd5_IDxOD0yN",
    "outputId": "db4fe478-ad0e-479c-aa41-9f9b1efa00d3"
   },
   "outputs": [],
   "source": [
    "np.sort(data['Income'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "Hp_0svcQD8kr",
    "outputId": "42e16872-af33-433f-8f88-891d2edc23ea"
   },
   "outputs": [],
   "source": [
    "np.sort(data['Experience'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 890
    },
    "colab_type": "code",
    "id": "GSC_FuVCFJBQ",
    "outputId": "7a8a4480-514c-42c2-9b07-1ce4eda72845"
   },
   "outputs": [],
   "source": [
    "np.sort(data['ZIP Code'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "GJaKzBCSFT5w",
    "outputId": "78234c2b-ad8b-4dbe-e1f5-979a3dd1bb4c"
   },
   "outputs": [],
   "source": [
    "np.sort(data['Family'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "colab_type": "code",
    "id": "oBzmZ3SsFo8Q",
    "outputId": "13d84746-2671-4dc5-ae51-b192e0acc3fe"
   },
   "outputs": [],
   "source": [
    "np.sort(data['CCAvg'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eCixWIJRF0HD",
    "outputId": "7a72278c-331a-49ff-f972-1d097152dc6b"
   },
   "outputs": [],
   "source": [
    "np.sort(data['Education'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "colab_type": "code",
    "id": "FrepgIxYGHR5",
    "outputId": "945dd02c-e123-417a-d07a-0121c185bbe0"
   },
   "outputs": [],
   "source": [
    "np.sort(data['Mortgage'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Y83HdtnJGU5i",
    "outputId": "e51785de-a73c-4ef3-df20-95cecdc1bb62"
   },
   "outputs": [],
   "source": [
    "np.sort(data['Personal Loan'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "GHiIAUrzGt0e",
    "outputId": "71ffd83d-e11d-4c18-f78f-843c9198910b"
   },
   "outputs": [],
   "source": [
    "np.sort(data['Securities Account'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hS2IT8lBG2V_",
    "outputId": "b1c9589c-0402-4119-9907-87c4ddfc1695"
   },
   "outputs": [],
   "source": [
    "np.sort(data['CD Account'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "TOAdl-5AHP2o",
    "outputId": "26a6f9c8-db3f-4417-91b9-343d07217157"
   },
   "outputs": [],
   "source": [
    "np.sort(data['Online'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "TD2kDvrHHT2u",
    "outputId": "b0619cde-45cd-4d8f-a1cc-a19a5d181280"
   },
   "outputs": [],
   "source": [
    "np.sort(data['CreditCard'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fw78FG2dWEBp"
   },
   "source": [
    "### **no of unique value in mortgage and other useful columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "VNqJ5cuQIiOm",
    "outputId": "3f6898da-c888-4d3d-8724-7ee1db7490c4"
   },
   "outputs": [],
   "source": [
    "data['Mortgage'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ZIP Code'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here the zip code is also like a serial number and had a lot of unique numbers i.e, 467 which are in a serial mostly, So we can remove this column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(labels='ZIP Code',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jxtv56GMWK7R"
   },
   "source": [
    "### **no of 0 value in mortgage and credit cards columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "iM2iS-t6ILQu",
    "outputId": "82776e4a-7562-462c-d5a9-0ef8030544e4"
   },
   "outputs": [],
   "source": [
    "data['Mortgage'].value_counts()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "A_MGp21qIaNx",
    "outputId": "2b2a06de-d5e4-4027-d66b-b3452e6deb46"
   },
   "outputs": [],
   "source": [
    "data['CreditCard'].value_counts()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a1AbQ40sWt-H"
   },
   "source": [
    "### **value counts of all the categorical columns using a for loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Education.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Family.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "lbo0SxKNJAi9",
    "outputId": "089b5147-5dfb-40a2-84a4-5653ecd1ffad"
   },
   "outputs": [],
   "source": [
    "for column in data.columns.to_list()[-5:]:\n",
    "  print(column+\": \\n\"+str(data[column].value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Visualization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3T8gPmyOW5Vr"
   },
   "source": [
    "## **Let us visualize the Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nN-VQv_5XIK7"
   },
   "source": [
    "**we use seaborn pairplot to get graphs between all columns and then visualize the rquired pairs of columns after deciding from pairplot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "tVXwC6fsJhqI",
    "outputId": "39504fcd-cf40-4f6e-a874-b89389461ff2"
   },
   "outputs": [],
   "source": [
    "sns.pairplot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0rt0AoH4XmVt"
   },
   "source": [
    "**It seems like age and experience are highly correlated**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dzQFkX4CXuYi"
   },
   "source": [
    "**Let us visualize them using a scatter plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 935
    },
    "colab_type": "code",
    "id": "ZkB12t8lRLFQ",
    "outputId": "8ca28185-1c61-4e0e-bd66-44cc70b79bda"
   },
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(16,16))\n",
    "plt.scatter(data.Age,data.Experience)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-YJ-bizoS-Wn"
   },
   "source": [
    "### It is very clear from the graph that experience and age are highly correlated and even a few violation on the left is also due to replacement of negative values in experience to median otherwise thier would be  a perfect correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From the above correlationtable we can say correlation between experience and age is almost one and we cannot find anyother significant correlation** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So now we can remove the experience column from the data since age can serve the purpose of both age and column at a time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(labels='Experience',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We will continue with our visualisation part**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We visualise each column individually so that we can know how they are distributed**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generally dont need to visualise last five binary columns since there will be only bars which represent the count of 1 and 0 which we had already seen in EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Age**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data.Age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mortgage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data.Mortgage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "most of the data has Mortgage is inbetween 0 and 200 and is positively skewed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CC Average**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data.CCAvg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "most of the data has cca average inbetween 0 and 3 and is positively skewed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Income**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data.Income)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "most of the people have income 8 and 70 and positively skewed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Family**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Family.value_counts().sort_index().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "most no of people have 1,2 or 4 family memebers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Education**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Education.value_counts().sort_index().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "most of the people have education level of 1 and the next highest is 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let us check for outliers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data.Income)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.boxplot(data['CCAvg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data['Mortgage'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can find that we have a few outliers in income, mortgage and cc average columns**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bivariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As our target variable is personal loan we mainly focus the plots containing the personal loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=data['Personal Loan'],y=data['Age'],data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=data['Personal Loan'],y=data['Income'],data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=data['Personal Loan'],y=data['CCAvg'],data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(data.Family,data['Personal Loan']).plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(data.Education,data['Personal Loan']).plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(data.Online,data['Personal Loan']).plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(data.CreditCard,data['Personal Loan']).plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(data['CD Account'],data['Personal Loan']).plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(data['Securities Account'],data['Personal Loan']).plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Heatmap**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax= plt.subplots(figsize=(15,10))\n",
    "sns.heatmap(data.corr(),cmap='plasma',annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Transform the features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this part we remove any outliers since we had already done the remaining required feature transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let us use any of the two methods to find the outliers 1) IQR 2) Z-SCORE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let us find first quantile, third quantile and inter quartile range**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1= data.quantile(0.25)\n",
    "q3= data.quantile(0.75)\n",
    "iqr=q3-q1\n",
    "iqr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let us remove the outliers that lie out of the 1.5 time iqr ranges**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=data[~((data<(q1-1.5*iqr))|(data>(q3+1.5*iqr)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It seems like we dont have any outliers  and so we do not need to remove anything so let us continue with the dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Z score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate the absolute values of z score for ease of comparison**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs=np.abs(zscore(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**remove the rows with absolute z score greater than 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter=(abs<3).all(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataf=data[filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in dataf.columns.to_list()[-5:]:\n",
    "  print(column+\": \\n\"+str(dataf[column].value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here if we remove the 800 rows it is clear that personal loan column would have only 0's i.e rows with 1's are all  removed , so we cannot build the model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As we have a lot of categorical data we better dont remove the outliers and we will continue with original data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we need to transform a few columns so that the skewedness that we observed in Univariate analysis can be removed**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We transform the age, income,ccaverage columns using log transform as remaining are categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As mortagage has so many zeros and the data is distributed very less after 100 we can better do binning process and convert mortgage to a categorical data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Mortgage'] = pd.cut(data['Mortgage'],bins=[0,100,200,300,400,500,600,700],labels=[0,1,2,3,4,5,6],include_lowest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Mortgage.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now let us extract age, income and cc avg columns so to reduce complex and long codes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datan=data[['Age','Income','CCAvg',]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We use log transform to remove the skewedness from these three columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datan=np.log(datan+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datan.isna().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let us check out how our columns are distributed after transformation and whether the skewedness is removed or not**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(datan.Income)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(datan.Age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(datan.CCAvg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Mortgage.value_counts().sort_index().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can see from the above graphs that we removed the skewness as much as possible and all of them look very much like normal data which is very useful for logistic regression model, now let us move on to normalising the data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Normalising and splitting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We use standard scaler to scale the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datan=scaler.fit_transform(datan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datan=pd.DataFrame(datan,columns=['Age','Income','CCAvg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we replace back the three columns we extracted previously from the main dataset as we have completed all the transformations and normalisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['Age','Income','CCAvg']]=datan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataf.isna().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are done with all the data analysis required from simple cleaning to complex scaling\n",
    "### Its time to move on to build our model with the cleaned and analytically prepared data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**befor building the model let us split our data into train and test sets**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that the tasrget variable personal loan has only 9 percent 1,s and remaining zero so here normal splitting would cause loss of enough 1's to either of train or test sets\n",
    "So we use stratified sampling in order to have good enough no of 1's in both train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First of all we split the data into x and y and then later we sperate for train and test in both x and y**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data.drop(labels='Personal Loan',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data[['Personal Loan']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtr,xts,ytr,yts= train_test_split(x,y,test_size=0.3,stratify=y,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let us check the value counts of ytrain and ytest and ensure considerable no of 1's are present in both**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytr.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yts.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**value counts look promising so let us move on to build the model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we implement and build the model and test for the accuracy**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**befor we fit the model we need to convert the ytrain to a numpy array and reshape it into required shape**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrn=ytr.to_numpy()\n",
    "ytrn=ytrn.reshape((3500,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0).fit(xtr, ytrn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us evaluate the accuracy score of the classification on train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(xtr,ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(xts,yts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here we did achieve accuracy of 95.6 percent in bith test and train set which is saying that our model is good in fitting and as well as predicting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As we completed our model next step is to evaluate the metrics so that we can get a clear understanding of our model and its performance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In order to evaluate metrics we need to get the prediction stes for training and test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrp=clf.predict(xtr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrp=pd.DataFrame(ytrp,columns=['Personal Loan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrp.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytsp=pd.DataFrame(clf.predict(xts),columns=['Personal Loan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytsp.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We are ready with the required predictions sets to evaluate metrics**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**let us evaluate different type of metrics**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the metrics library from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(ytr,ytrp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(yts,ytsp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(ytr,ytrp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(yts,ytsp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.balanced_accuracy_score(ytr,ytrp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.balanced_accuracy_score(yts,ytsp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We got this value 0.82 which is close to 1 so this metric was good**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.average_precision_score(ytr,ytrp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.average_precision_score(yts,ytsp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This value 0.6 is not so close to one but somewhat good enough**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.f1_score(ytr,ytrp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.f1_score(yts,ytsp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F1 Score is close to 0.74 which seems to be good enough since this is a cumulative measure of both precision and recall**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.log_loss(ytr,ytrp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.log_loss(yts,ytsp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mathew Correlation Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.matthews_corrcoef(ytr,ytrp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.matthews_corrcoef(yts,ytsp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here we got value 0.73 close to 1 so this is good**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision and Recall values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.recall_score(ytr,ytrp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.precision_score(ytr,ytrp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.recall_score(yts,ytsp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.precision_score(yts,ytsp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recall is somewhat low i.e, 0.66 but precesion is high i.e, 0.84 so overall we are having good tradeoff between precesion and recall**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC AUC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.roc_auc_score(ytr,ytrp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.roc_auc_score(yts,ytsp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here we got roc auc value 0.82 which is greater than 0.5 and somewhat close to 1 so therefore we can sy that this is good enough**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion:-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We can say that almost all of the metrics are giving good values especially f1 score and accuracy\n",
    "2. So our basic regression model is working well on the transformed data\n",
    "3. So the transformations on data are correct and we can proceed furthur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8) Other classification algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Its time we check our data with other classification metrics and check how our data responds as already our logistic classifier is doing good**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Support Vector Machine ( SVM )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(random_state=1).fit(xtr,ytrn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(xtr,ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(xts,yts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix for test set\n",
    "ytsp=pd.DataFrame(clf.predict(xts),columns=['Personal Loan'])\n",
    "print(metrics.confusion_matrix(yts,ytsp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With SVM Algorithm we achieved a high accuracy of 97.6 and 98% which is an improvement to our normal classification model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth=8,random_state=0).fit(xtr,ytrn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(xtr,ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(xts,yts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix for test set\n",
    "ytsp=pd.DataFrame(clf.predict(xts),columns=['Personal Loan'])\n",
    "print(metrics.confusion_matrix(yts,ytsp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With decision tree Algorithm we achieved 99.5% accuracy on training set and 98% on test set which is an improvement to our SVM model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) Random Forest ( Ensemble Method )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=10,max_depth=8,random_state=0).fit(xtr,ytrn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(xtr,ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(xts,yts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix for test set\n",
    "ytsp=pd.DataFrame(clf.predict(xts),columns=['Personal Loan'])\n",
    "print(metrics.confusion_matrix(yts,ytsp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With random forest Algorithm we achieved the best performance till now since we got 99.5% and 98.5% accuracy**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d) Extra Trees Classifier ( Ensemble Method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ExtraTreesClassifier(n_estimators=10, max_depth=12,min_samples_split=2, random_state=0).fit(xtr,ytrn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(xtr,ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(xts,yts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix for test set\n",
    "ytsp=pd.DataFrame(clf.predict(xts),columns=['Personal Loan'])\n",
    "print(metrics.confusion_matrix(yts,ytsp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This Algorithm was most extra careful on training set as it has 98.7% accuracy but doing relatively poor on test set with 97.8 accuracy which is less than random forest accuracy**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e) Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0).fit(xtr,ytrn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(xtr,ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(xts,yts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix for test set\n",
    "ytsp=pd.DataFrame(clf.predict(xts),columns=['Personal Loan'])\n",
    "print(metrics.confusion_matrix(yts,ytsp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradient boosting performed similar to SVM with 98 and 97.6 accuracies which is good but not up to the level of Ensemble Methods**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion :-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We had fit 5 other models other than logistic regression and calculated accuracies \n",
    "2. Of all the 5 it is clear that Ensemble methods are performing well than any other Algorithm with accuracies close to 99%\n",
    "3. SVM and Gradient boosting performed good after Ensemble methods with accuracies close to 98%\n",
    "4. Therfore, Ensemble methods are the best Algorithms for classifications especially in this type of problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We have completed our project, before closing let us give a business understanding of our project**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9) Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally we are done with our project, so let us bring all the important points from different stages of our model and put them together for giving a business insights and understandings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So there are two main parts where we can give a report they are EDA and model parts, so let us check them seperately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1:- EDA  and univariate / bivariate analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First thing we observed is experience and age are highly correlated.\n",
    "2. The age among people is almost unifromly distributed which means all age groups are more or less in equal number.\n",
    "3. CCAvg, Income and mortgage tend to be more skewed that is groups of large no of people have similar values among them than other groups with other values.\n",
    "4. coming to features and their impacts on personal loan as this is what our concern, Its seems like age has no or very less impact on loan chance\n",
    "5. more income has some positive impact on loan\n",
    "6. more CC Average has very good positive impact on loan\n",
    "7. Family has a positive impact on loan when increasing from 1 to 3 family members and bit negative when moving from 3 to 4 family members\n",
    "8. more Education has good impact on loan chance\n",
    "9. Online has no or very less impact on loan\n",
    "10. Credit card has negative impact on loan\n",
    "11. CD Account and Securities account has negative impact on loan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Concluding this part we can say a person with more income, more CC average, with 2 or 3 family members, with more education, and with no credit card will get personal loan irrespective of other factors**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If we check for an ideal person with all these specifications we must get one**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=pd.DataFrame({'Age':0,'Income':1,'Family':3,'CCAvg':1,'Education':3,'Mortgage':0,'Securities Account':0,'CD Account':0,'Online':0,'CreditCard':0},index=range(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction of an ideal person with all good specifications\n",
    "clf.predict(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We got 1 which means that the specified conditions satisfy the model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 :- Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We will check all the models and then prefer the best one to use**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train accuracy : 95.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test accuracy  : 95.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "confusion matrix:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1338 ,   18]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  [ 48 ,    96]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "false negative = 48\n",
    "\n",
    "false positive = 18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train accuracy : 97.6\n",
    "\n",
    "test accuracy : 98\n",
    "\n",
    "confusion matrix:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1353  ,  3]\n",
    "\n",
    "[  27 , 117]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "false negative = 27\n",
    "\n",
    "false positive = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decesion Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train accuracy : 99.5\n",
    "\n",
    "test accuracy : 98.26\n",
    "\n",
    "confusion matrix:\n",
    "\n",
    "[1345  ,  11]\n",
    " \n",
    " [  15 ,  129]\n",
    "\n",
    "false negative = 15\n",
    "\n",
    "false positive = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train accuracy : 99.5\n",
    "\n",
    "test accuracy : 98.36\n",
    "\n",
    "confusion matrix:\n",
    "\n",
    "[1349 , 7]\n",
    "\n",
    "[ 16 , 128]\n",
    "\n",
    "false negative = 16\n",
    "\n",
    "false positive = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extrem Tree classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train accuracy : 98.7\n",
    "\n",
    "test accuracy : 96.8\n",
    "\n",
    "confusion matrix:\n",
    "\n",
    "[1353 , 3]\n",
    "\n",
    "[ 45 , 90]\n",
    "\n",
    "false negative = 45\n",
    "\n",
    "false positive = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train accuracy : 98\n",
    "\n",
    "test accuracy : 97.6\n",
    "\n",
    "confusion matrix:\n",
    "\n",
    "[1349 , 7]\n",
    "\n",
    "[ 28 , 116]\n",
    "\n",
    "false negative = 28\n",
    "\n",
    "false positive = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion of PART 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**After comparing all the models we can say that the random forest algorithm is the best model with high accuracies and very less false positives and negatives**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Therefore use random forests algorithm**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THANK YOU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NAME :-YARRU LAKSHMI SAI KRISHNA\n",
    "\n",
    "EMAIL :- yarrulakshmisai111@gmail.com"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "RWAxHJI0szqz",
    "TDFE5CtbVHV9"
   ],
   "name": "bank personal loan modelling",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
